
import os
import tweepy
from tweepy import OAuthHandler
import json

consumer_key = os.environ['CONSUMERKEY']
consumer_secret = os.environ['CONSUMERSECRET']
access_token = os.environ['ACCESSTOKEN']
access_secret = os.environ['ACCESSSECRET']

auth = OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_secret)

api = tweepy.API(auth)
user = api.me()

print('Name: ' + user.name)
print('Location: ' + user.location)
print('Friends: ' + str(user.followers_count))
print('Created: ' + str(user.created_at))
print('Description: ' + str(user.description))
# we use 1 to limit the number of tweets we are reading
# and we only access the `text` of the tweet
for status in tweepy.Cursor(api.home_timeline).items(1):
            print(status.text)
for status in tweepy.Cursor(api.home_timeline).items(1):
           print(json.dumps(status._json, indent=2))
for friend in tweepy.Cursor(api.friends).items(1):
           print(json.dumps(friend._json, indent=2))
emoticons_str = r"""
    (?:
            [:=;] # Eyes
                    [oO\-]? # Nose (optional)
                            [D\)\]\(\]/\\OpP] # Mouth
                                )"""
regex_str = [
                                             emoticons_str,
                                                 r'<[^>]+>', # HTML tags
                                                     r'(?:@[\w_]+)', # @-mentions
                                                         r"(?:\#+[\w_]+[\w\'_\-]*[\w_]+)", # hash-tags
                                                             r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs

                                                                 r'(?:(?:\d+,?)+(?:\.?\d+)?)', # numbers
                                                                     r"(?:[a-z][a-z'\-_]+[a-z])", # words with - and '
                                                                         r'(?:[\w_]+)', # other words
                                                                             r'(?:\S)' # anything else
                                                                             ]

tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)
emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)

def tokenize(s):return tokens_re.findall(s)
def preprocess(s, lowercase=False):
        tokens = tokenize(s)
        if lowercase:
            tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]
        return tokens
for tweet in tweepy.Cursor(api.user_timeline).items(1):print(preprocess(tweet.text))